# -*- coding: utf-8 -*-
"""Assignment1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DUxD5BR5Uz0klCCe2G_BtGnUDt-v71LN

#Dataset setup

Imports
"""

import torch
import numpy as np
from torch.utils.data import Dataset
from torchvision import datasets
import torchvision.transforms as transforms
import torchvision.models as models
import matplotlib.pyplot as plt
from scipy.stats import norm
from torch import nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from tqdm import tqdm
from torch.utils.data.dataset import TensorDataset
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.model_selection import learning_curve
from sklearn.naive_bayes import GaussianNB
from sklearn import svm
from sklearn.model_selection import GridSearchCV
import random

"""Loading the train and test datasets"""

training_data = datasets.MNIST(
    root="data",
    train=True,
    download=True,
    transform=transforms.ToTensor()
)
test_data = datasets.MNIST(
    root="data",
    train=False,
    download=True,
    transform=transforms.ToTensor()
)

training_X = []; training_y = []; test_X = []; test_y = []
for x, y in training_data:
  training_X.append(x)
  training_y.append(y)
for x, y in test_data:
  test_X.append(x)
  test_y.append(y)

"""Plotting digits in the dataset"""

figure = plt.figure(figsize=(8, 8))
cols, rows = 3, 3
for i in range(1, cols * rows + 1):
    sample_idx = torch.randint(len(training_data), size=(1,)).item()
    img, label = training_data[sample_idx]
    figure.add_subplot(rows, cols, i)
    plt.title(label)
    plt.axis("off")
    plt.imshow(img.squeeze(), cmap="gray")
plt.show()

"""Average digit"""

dig_dict = {}
for i in range(len(training_data)):
  img, label = training_data[i]
  dig_dict.setdefault(label, []).append(img)

prototype = {}
for y in dig_dict:
  prototype[y] = torch.cat(dig_dict[y], 0).mean(dim=0)

for x in prototype:
  plt.title(x)
  plt.axis("off")
  plt.imshow(prototype[x].squeeze(), cmap="gray")
  plt.show()

"""Standard deviation digit"""

epsilon = 10**-5
stddevs = {}
for y in dig_dict:
  stddevs[y] = torch.cat(dig_dict[y], 0).std(dim=0) + epsilon

for x in stddevs:
  plt.title(x)
  plt.axis("off")
  plt.imshow(stddevs[x].squeeze(), cmap="gray")
  plt.show()

"""#Euclidean classifier

Scikit-learn Euclidean classifier
"""

class EuclideanClassifier(BaseEstimator, ClassifierMixin):  
  """Classify samples based on the distance from the mean feature value"""

  def __init__(self):
    self.X_mean_ = None

  def fit(self, X, y):
    """
    This should fit classifier. All the "work" should be done here.
    
    Calculates self.X_mean_ based on the mean 
    feature values in X for each class.
    
    self.X_mean_ becomes a numpy.ndarray of shape 
    (n_classes, n_features)
    
    fit always returns self.
    """
    dig_dict = {}
    for i in range(len(X)):
      img = X[i]
      label = y[i]
      dig_dict.setdefault(label, []).append(img)
    dig_keys = list(dig_dict.keys())
    dig_keys.sort()
    dig_dict = {i: dig_dict[i] for i in dig_keys}
    self.X_mean_ = []
    for y in dig_dict:
      a = torch.cat(dig_dict[y], dim=0).mean(dim=0).numpy()
      self.X_mean_.append(a)
    self.X_mean_ = np.array(self.X_mean_)
    return self

  def predict(self, X):
    """
    Make predictions for X based on the
    euclidean distance from self.X_mean_
    """
    preds = []
    for i in range(len(X)):
      distance = [((v - X[i]) ** 2).sum().item() for v in torch.from_numpy(self.X_mean_)]
      pred = distance.index(min(distance))
      preds.append(pred)
    return preds
  
  def score(self, X, y):
    """
    Return accuracy score on the predictions
    for X based on ground truth y
    """
    correct = 0
    for i in range(len(X)):
      distance = [((v - X[i]) ** 2).sum().item() for v in torch.from_numpy(self.X_mean_)]
      pred = distance.index(min(distance))
      if(pred == y[i]):
        correct += 1
    score = correct/len(y)
    return score

model = EuclideanClassifier()

model.fit(training_X, training_y)

model.score(test_X, test_y)

"""Learning curve plot for different train sizes


"""

train_sizes, train_scores, test_scores = learning_curve(estimator=EuclideanClassifier(), X=training_X, y=training_y, train_sizes=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cv=3)

train_scores_mean = train_scores.mean(axis=1)
test_scores_mean = test_scores.mean(axis=1)

plt.plot(train_sizes, train_scores_mean, label="Train", marker="o")
plt.plot(train_sizes, test_scores_mean, label="Test", marker="o")
plt.legend(loc="lower right")
plt.show()

"""#Dimensionality reduction for plotting

Naive plot of empirical distribution of data
"""

# Naive approach: try grabbing n random pixels and use those to display the data on a grid
class MyNaiveClassifier():  
  def __init__(self, n_components):
    self.n_components = n_components
    self.components = np.zeros(n_components)

  def fit(self, X):
    X_flatten = torch.flatten(X, start_dim=1)
    d = X_flatten.size(1)
    for i in range(self.n_components):
      while True:
        self.components[i] = random.randint(0, d-1)
        unique = True
        for j in range(i):
          if(self.components[j] == self.components[i]):
            unique = False
        if unique:
          break
    return self
  
  def transform(self, X):
    X_flatten = torch.flatten(X, start_dim=1)
    return X_flatten[:,self.components]
  
  def fit_transform(self, X):
    self.fit(X)
    return self.transform(X)

training_X = []; training_y = []; test_X = []; test_y = []
for x, y in training_data:
  training_X.append(x)
  training_y.append(y)
for x, y in test_data:
  test_X.append(x)
  test_y.append(y)
training_X = torch.cat(training_X)
test_X = torch.cat(test_X)
training_y = torch.tensor(training_y)
test_y = torch.tensor(test_y)

model = MyNaiveClassifier(n_components=100)
model.fit_transform(training_X).shape

s = set(model.components)
len(s) == len(model.components)

"""Principal Component Analysis (PCA)"""

# TODO

"""#Naive Bayes classifier

Naive Bayes classifier as scikit-learn estimator
"""

class NaiveBayes(BaseEstimator, ClassifierMixin):  

  def __init__(self, ep):
    self.ep = ep
    self.freq = None
    self.means = None
    self.stddevs = None

  def fit(self, X, y):
    dig_dict = {}
    for i in range(len(X)):
      img = X[i]
      label = y[i]
      dig_dict.setdefault(label, []).append(img)
    dig_keys = list(dig_dict.keys())
    dig_keys.sort()
    dig_dict = {i: dig_dict[i] for i in dig_keys}
    self.freq = []
    self.means = []
    self.stddevs = []
    for y in dig_dict:
      self.freq.append(len(dig_dict[y]) / len(X))
      self.means.append(torch.cat(dig_dict[y], dim=0).mean(dim=0).numpy())
      self.stddevs.append((torch.cat(dig_dict[y], dim=0).std(dim=0) + self.ep).numpy())
    self.freq = np.array(self.freq)
    self.means = np.array(self.means)
    self.stddevs = np.array(self.stddevs)
    return self

  def predict(self, X):
    return 0

  def score(self, X, y):
    correct = 0
    for i in range(len(X)):
      '''
      Numerical instabilities with original naive Bayes formula:
      - Some pixels have 0 deviation: add small constant (epsilon) to all deviations, or clipping
      - PDF is not bounded from above, so product of these large values can result in infinity: compute log-probabilities
        - Relative order is preserved since log is increasing function, and breaks products into sums
      - Log approaches negative infinity when probability approaches 0: clip to interval (lower bound), or add small constant 
      '''
      prob = [np.log(np.clip(norm.pdf(X[i], self.means[y], self.stddevs[y]).squeeze(), 10**-10, None)).sum() + np.log(self.freq[y]) for y in range(len(self.freq))]
      pred = prob.index(max(prob))
      if pred == y[i]:
        correct += 1
    return correct/len(X)*100

model = NaiveBayes(ep=10**-5)

model.fit(training_X, training_y)

model.score(test_X, test_y)

"""GaussianNB (sklearn built-in estimator)"""

training_X = torch.cat(training_X)
test_X = torch.cat(test_X)
training_y = torch.tensor(training_y)
test_y = torch.tensor(test_y)

training_X = torch.flatten(training_X, start_dim=1)
test_X = torch.flatten(test_X, start_dim=1)

gnb = GaussianNB()
gnb.fit(training_X, training_y)
y_pred = torch.from_numpy(gnb.predict(test_X))

print(torch.sum(y_pred == test_y).item()/len(test_y)*100)

"""#SVM

Support vector classification
"""

clf = svm.LinearSVC() # LinearSVC is a faster implementation of SVC for the case of a linear kernel, used with large datasets

clf.fit(training_X, training_y)

clf.score(test_X, test_y)

"""#Neural networks

Neural network architecture
"""

w = training_X.shape[-2]
h = training_X.shape[-1]

class NeuralNetwork(nn.Module):
  # The constructor to your Module only initializes your layer types 
  # PyTorch keeps track of these variables, but it has no idea how the layers connect to each other
  def __init__(self):
    super().__init__()
    self.layer1 = nn.Linear(w * h, 100)
    self.layer2 = nn.Linear(100, 10)
  # For PyTorch to understand the network architecture youâ€™re building, you define the forward function
  # Inside the forward function you take the variables initialized in your constructor and connect them
  def forward(self, x: torch.Tensor) -> torch.Tensor:
    x = self.layer1(x.flatten(start_dim=1))
    x = F.relu(x)
    x = self.layer2(x)
    return x

"""Feedforward neural network model"""

training_X = []; training_y = []; test_X = []; test_y = []
for x, y in training_data:
  training_X.append(x)
  training_y.append(y)
for x, y in test_data:
  test_X.append(x)
  test_y.append(y)
training_X = torch.cat(training_X)
test_X = torch.cat(test_X)
training_y = torch.tensor(training_y)
test_y = torch.tensor(test_y)

class NeuralNet(BaseEstimator, ClassifierMixin):  

    def __init__(self, lr=1e-2, opt_class=optim.SGD, num_epochs=10, weight_decay=0, loss_function=nn.CrossEntropyLoss(), batch_size=64):
        self.nn = NeuralNetwork()
        self.lr = lr
        self.opt_class = opt_class
        self.weight_decay = weight_decay
        self.batch_size = batch_size
        self.num_epochs = num_epochs
        self.optimizer = opt_class(self.nn.parameters(), lr=self.lr, weight_decay=self.weight_decay)
        self.loss_function = loss_function

    def fit(self, X, y):
        self.nn.train()
        dataset = TensorDataset(X, y)
        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)
        for epoch in range(self.num_epochs):
          for x, y_lbl in tqdm(dataloader, desc=f"Epoch {epoch+1}"):
            y_pred = self.nn(x)
            loss = self.loss_function(y_pred, y_lbl)
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
        return self

    def predict(self, X):
      self.nn.eval()
      preds = []
      dataloader = DataLoader(X, batch_size=self.batch_size)
      with torch.no_grad():
        for x in dataloader:
          y_pred = self.nn(x)
          preds.append(y_pred)
      return torch.cat(preds).argmax(dim=-1)
    
    def score(self, X, y):
      preds = self.predict(X)
      s = (y == preds).sum()
      return (s/len(y)).item()

learning_rate = 1e-2
num_epochs = 10
batch_size = 64
weight_decay = 0

model = NeuralNet(learning_rate, optim.SGD, num_epochs, weight_decay, nn.CrossEntropyLoss(), batch_size)
model.fit(training_X, training_y)
model.score(test_X, test_y)

"""Grid search for finetuned hyperparameters"""

param_grid = {
    'lr': [1e-2], 
    'opt_class': [optim.SGD, optim.Adam], 
    'num_epochs': [10], 
    'weight_decay': [0, 1e-3], 
    'loss_function': [nn.CrossEntropyLoss()], 
    'batch_size': [64],
}

estimator = NeuralNet()

gs_nn = GridSearchCV(estimator, param_grid, cv=3, n_jobs=-1, verbose=10)

gs_nn.fit(training_X, training_y)

gs_nn.best_params_

gs_nn.score(test_X, test_y)

"""Image augmentation (torchvision.transforms)"""

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.RandomInvert(0.5),
    transforms.RandomApply([transforms.RandomRotation(degrees=(-30, 30))], p=0.5),
    transforms.CenterCrop(20)
])

bad_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5)
])

training_data = datasets.MNIST(
    root="data",
    train=True,
    download=True,
    transform=transform
)
test_data = datasets.MNIST(
    root="data",
    train=False,
    download=True,
    transform=transforms.ToTensor()
)

figure = plt.figure(figsize=(8, 8))
cols, rows = 3, 3
for i in range(1, cols * rows + 1):
    sample_idx = 1
    img, label = training_data[sample_idx]
    figure.add_subplot(rows, cols, i)
    plt.title(label)
    plt.axis("off")
    plt.imshow(img.squeeze(), cmap="gray")
plt.show()

"""Convolutional neural network"""

class LeNet(nn.Module):
  def __init__(self, numChannels, classes):
    # call the parent constructor
    super().__init__()
    # initialize first set of CONV => RELU => POOL layers
    self.conv1 = nn.Conv2d(in_channels=numChannels, out_channels=20,
      kernel_size=(5, 5))
    self.relu1 = nn.ReLU()
    self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))
    # initialize second set of CONV => RELU => POOL layers
    self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))
    self.relu2 = nn.ReLU()
    self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))
    # initialize first (and only) set of FC => RELU layers
    self.fc1 = nn.Linear(in_features=800, out_features=500)
    self.relu3 = nn.ReLU()
    # initialize our softmax classifier
    self.fc2 = nn.Linear(in_features=500, out_features=classes)

  def forward(self, x):
    # pass the input through our first set of CONV => RELU => POOL layers
    x = self.conv1(x)
    x = self.relu1(x)
    x = self.maxpool1(x)
    # pass the output from the previous layer through the second set of CONV => RELU => POOL layers
    x = self.conv2(x)
    x = self.relu2(x)
    x = self.maxpool2(x)
    # flatten the output from the previous layer and pass it through our only set of FC => RELU layers
    x = x.flatten(start_dim=1)
    x = self.fc1(x)
    x = self.relu3(x)
    # pass the output to our softmax classifier to get our output
    # predictions
    x = self.fc2(x)
    # return the output predictions
    return x

class ConvNeuralNet(BaseEstimator, ClassifierMixin):  

    def __init__(self, lr=1e-2, opt_class=optim.SGD, num_epochs=10,
                 weight_decay=0, loss_function=nn.CrossEntropyLoss(), batch_size=64, num_channels=1, classes=10, device="cpu"):
        self.device = device
        self.classes = classes
        self.num_channels = num_channels
        self.nn = LeNet(num_channels, classes).to(device)
        self.lr = lr
        self.opt_class = opt_class
        self.weight_decay = weight_decay
        self.batch_size = batch_size
        self.num_epochs = num_epochs
        self.optimizer = opt_class(self.nn.parameters(), lr=self.lr, weight_decay=self.weight_decay)
        self.loss_function = loss_function
        self.training_history = []

    def fit(self, X, y, X_val=None, y_val=None):
        self.nn.train()
        self.nn = self.nn.to(self.device)
        dataset = TensorDataset(X[:, None], y) # X[:, None] adds dimension for num_channels
        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)
        for epoch in range(self.num_epochs):
          for x, y_lbl in tqdm(dataloader, desc=f"Epoch {epoch+1}"):
            x, y_lbl = x.to(self.device), y_lbl.to(self.device)
            y_pred = self.nn(x)
            loss = self.loss_function(y_pred, y_lbl)
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
          if X_val != None and y_val != None:
            accuracy = self.score(X_val, y_val)
            self.training_history.append(accuracy)
            print(f"Epoch {epoch+1}: {accuracy}")
        return self

    def predict(self, X):
      self.nn.eval()
      self.nn = self.nn.to(self.device)
      preds = []
      dataloader = DataLoader(X[:, None], batch_size=self.batch_size)
      with torch.no_grad():
        for x in dataloader:
          x = x.to(self.device)
          y_pred = self.nn(x).cpu()
          preds.append(y_pred)
      return torch.cat(preds).argmax(dim=-1)
    
    def score(self, X, y):
      preds = self.predict(X)
      s = (y == preds).sum()
      return (s/len(y)).item()

training_X = []; training_y = []; test_X = []; test_y = []
for x, y in training_data:
  training_X.append(x)
  training_y.append(y)
for x, y in test_data:
  test_X.append(x)
  test_y.append(y)
training_X = torch.cat(training_X)
test_X = torch.cat(test_X)
training_y = torch.tensor(training_y)
test_y = torch.tensor(test_y)

model = ConvNeuralNet(learning_rate, optim.SGD, 20, weight_decay, nn.CrossEntropyLoss(), batch_size, 1, 20, "cuda:0")

model.fit(training_X, training_y, test_X, test_y)

plt.plot(model.training_history, marker="o")
plt.show()

model.score(test_X, test_y)

print(model.nn.conv1.weight)
print(model.nn.conv1.bias)

param_grid = {
    'lr': [1e-2], 
    'opt_class': [optim.SGD], 
    'num_epochs': [10, 20, 30, 40], 
    'weight_decay': [0], 
    'loss_function': [nn.CrossEntropyLoss()], 
    'batch_size': [64],
    'num_channels': [1],
    'classes': [10],
    'device': ["cuda:0"]
}

estimator = ConvNeuralNet()

gs_nn = GridSearchCV(estimator, param_grid, cv=3)

gs_nn.fit(training_X, training_y)

gs_nn.best_params_

gs_nn.score(test_X, test_y)

list(model.nn.children())[:-2]

"""Saving and reloading trained model"""

torch.save(model, 'model.pth')

model = torch.load('model.pth')

model.score(test_X, test_y)

"""#Representation learning

Embeddings
"""

class LeNetEmbeddings(nn.Module):
  def __init__(self, cnn):
    # call the parent constructor
    super().__init__()
    self.cnn = cnn

  def forward(self, x):
    # pass the input through our first set of CONV => RELU => POOL layers
    x = self.cnn.conv1(x)
    x = self.cnn.relu1(x)
    x = self.cnn.maxpool1(x)
    # pass the output from the previous layer through the second set of CONV => RELU => POOL layers
    x = self.cnn.conv2(x)
    x = self.cnn.relu2(x)
    x = self.cnn.maxpool2(x)
    # flatten the output from the previous layer and pass it through our only set of FC => RELU layers
    x = x.flatten(start_dim=1)
    x = self.cnn.fc1(x)
    return x

feature_extractor = LeNetEmbeddings(model.nn.cpu()).to("cuda:0").eval()

training_embeddings = []
dataset = TensorDataset(training_X[:, None], training_y)
dataloader = DataLoader(dataset, shuffle=True)
for x, y_lbl in dataloader:
  x, y_lbl = x.to("cuda:0"), y_lbl.to("cuda:0")
  with torch.no_grad():
    embedding = feature_extractor(x).cpu()
  training_embeddings.append(embedding)
# The only things you put in the GPU are the model, its parameters, and the specific batch that you are computing
# But once you finish computing you move the data back to the CPU

training_embeddings = torch.cat(training_embeddings, dim=0)
training_embeddings.shape # Compression from 28 x 28 => 500 (not a lot of compression, but with larger RGB images it's a much compressed representation)

test_embeddings = []
dataset = TensorDataset(test_X[:, None], test_y)
dataloader = DataLoader(dataset, shuffle=True)
for x, y_lbl in dataloader:
  x, y_lbl = x.to("cuda:0"), y_lbl.to("cuda:0")
  with torch.no_grad():
    embedding = feature_extractor(x).cpu()
  test_embeddings.append(embedding)

clf = EuclideanClassifier()

clf.fit(training_embeddings, training_y)

clf.score(test_embeddings, test_y)

"""Autoencoders"""

class Autoencoder(nn.Module):
  def __init__(self):
    self.encoder = nn.Sequential(
        nn.Linear(28 * 28, 64),
        nn.ReLU()
    )
    self.decoder = nn.Sequential(
        nn.Linear(64, 28 * 28),
        nn.Sigmoid()
    )

  def forward(self, x):
    x = self.decoder(self.encoder(x))
    return x